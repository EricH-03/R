---
title: "Stat 260 Assignment 3"
author: "Eric Huber"
date: "08/04/2022"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Question 1:

```{r, q1a}
tomato_soup = c(520,515,516,517,519,522,513)
t.test(tomato_soup, conf.level =0.96 )
```
### (1.a) 
The 96% confidence interval is (514.3664, 520.4907)

### (1.b)
515 is a reasonable estimate for our true mean because it falls in the roughly in the middle of the confidence interval. It is also somewhat close to our sample mean which is ~517

## Question 2:

### (2.a)
```{r, q2a}
concrete_slab = c(35.1,34.4,35.8,36.1,37.7)
t.test(concrete_slab, mu = 35, alternative = "greater" )
```
### (2.b)
Our observed value of our test statistic is 1.479.

### (2.c)
Our p-value is 0.1066

### (2.d)
Since 0.1066 > 0.01, then p > Î± . Thus we fail to reject the null hypothesis.


## Question 3:


### (3.a)
```{r,q3a}
brand1 = c(580,592,588,589,581)
brand2 = c(579,582,577,591,583)

sd(brand1)
sd(brand2)

sd(brand1)/sd(brand2)
```
Since the ratio is ~0.98 which is less than 1.4 we should use pooled procedures.

### (3.b)
```{r,q2b}
t.test(brand1, brand2, mu = 0, alternative = "two.sided", var.equal = TRUE)
```

### (3.c)
The p-value for our test is 0.3146

### (3.d)
Since the p-value is greater than 0.1 there is little to not evidence against the null hypothesis


## Question 4:


### (4.a)
```{r,q4a}
x1 <- c(130,103,116,113,124,122,128,124,123,108,134,108,111,129,134) # for Pre
x2 <- c(134,106,110,115,122,126,130,118,125,110,138,111,115,125,130) # for Post

t.test(x1,x2, mu = 0, alternative = "two.sided", paired = TRUE, conf.level = 0.95)
```
The 95% confidence interval is (-2.635481,  1.568815)

### (4.b)
```{r,4b}
t.test(x1,x2, mu = 0, alternative = "two.sided", paired = TRUE)
```
Since our null hypothesis was that there is no difference in between our treatments (ie the true difference in our mean IS 0). So we can look at our p-value, which is ~0.5949 this is greater than 0.1, which tells us there's little or no evidence against our null hypothesis. So well fail to reject the claim that there is no difference in the pre vs post group.

### (4.c)
The observed value of the test statistic is -0.54415

### (4.d)
It is a t-type distribution with 28 degrees of freedom.

### (4.e)
The p-value  is 0.8834


## Question 5 and 6:

## 5:
paste image here
```{r, 5}
Usim <- function(repeats, size){
  v <- rexp(size*repeats, rate = 0.2)               #generate size*repeats from Uniform(0,1)
  w <- matrix(v,nrow=size,ncol=repeats)  #Put v in a matrix with size rows and repeats cols
  return(colMeans(w))  #Sum the columns
}


set.seed(12345)  # Make simulation random but reproducible

U1 <- Usim(10000,1)   #size 1
head(U1)

U2 <- Usim(10000,10)   #size 10
head(U2)

U3 <- Usim(10000,30)   #size 30
head(U3)

U4 <- Usim(10000,50)  #size 50
head(U4)     # sums of 20 U(0,1) random observations
length(U4)   #check the length, should be 10000

layout(matrix(c(1,2,3,4),nrow=2,ncol=2,byrow=TRUE))  

hist(U1,prob=TRUE,ann=FALSE)   #ann=FALSE turns off annotation
title("n = 1")

hist(U2,prob=TRUE,ann=FALSE) 
title("n = 10")

hist(U3,prob=TRUE,ann=FALSE) 
title("n = 30")

hist(U4,prob=TRUE,ann=FALSE) 
title("n = 50")

layout(1)
```

### 6:
```{r,6}
set.seed(12345)  # Make simulation random but reproducible

CI <- c(0,0)
count1 <- 0

for (i in 1:5000){
  x <- rnorm(100)
  CI[1] <- mean(x) - qnorm(0.965)/10      # compute lower confidence limit
  CI[2] <- mean(x) + qnorm(0.965)/10      # compute upper confidence limit
  if(CI[1] <= 0 & CI[2] >= 0) {           # check if true mean is inside the confidence interval
    count1 <- count1 + 1
  }
}

count1

cat("Percentage of confidence intervals containing mu = ", count1/50, "\n")
```
The Percentage of confidence intervals containing mu was 92.92. We replaced the number 0.975 with 0.965.

